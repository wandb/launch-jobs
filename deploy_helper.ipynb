{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Page Loading Helper\n",
    "\n",
    "This notebook provides tooling to populate a jobs page from scratch using images from the [wandb dockerhub](https://hub.docker.com/u/wandb).\n",
    "\n",
    "Tooling includes:\n",
    "1. Create job from docker image\n",
    "2. Rename job to user-friendly name\n",
    "3. Add example runs that will auto-populate the run's `Clone from...` menu\n",
    "4. Delete the dummy run used to create the job initially\n",
    "\n",
    "Notes:\n",
    "1. This notebook uses a [special branch of the SDK](https://github.com/wandb/wandb/tree/andrew/helpers) with helpful GQL mutations added.  Please install that branch for now until it's merged into main.\n",
    "2. Jobs prefixed with `gpu_` require a GPU to run and are added to a GPU queue by default.  Please make sure you have a GPU  agent available to run these jobs, otherwise no runs will be populated.\n",
    "3. You must have queues running to populate jobs!\n",
    "4. The `sql_query` job currently does not work on M1.  This is due to upstream issues with emulation and lack of linux/arm64 support for the `connectorx` package.  The job should still work on an `amd64` machine."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repo settings\n",
    "JOB_REPO_ENTITY = 'launch-test'\n",
    "JOB_REPO_PROJECT = 'jobs'\n",
    "\n",
    "# Queue settings\n",
    "CPU_QUEUE_NAME = 'andrew-cpu'\n",
    "GPU_QUEUE_NAME = 'andrew-gpu'\n",
    "\n",
    "# Job/image settings\n",
    "DOCKER_IMAGE_TAG = '134fcaf3d4b1499e69b426fad803b7e2cca85ab5'\n",
    "JOBS_DIR = 'jobs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env(envlist):\n",
    "    env = {}\n",
    "    with open(envlist) as f:\n",
    "        for line in f.read().splitlines():\n",
    "            k, v = line.split('=')\n",
    "            env[k] = v\n",
    "    \n",
    "    return env\n",
    "\n",
    "job_repo_base_env = get_env(\"/Users/andrewtruong/.wandb_launch/env.list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import platform\n",
    "import click\n",
    "import docker\n",
    "import yaml\n",
    "\n",
    "import wandb\n",
    "from wandb.sdk.internal.internal_api import Api as InternalApi\n",
    "from wandb.sdk.launch import launch_add\n",
    "\n",
    "\n",
    "api = wandb.Api()\n",
    "iapi = InternalApi()\n",
    "LOADER_STR = \"__loader-delete-me__\"\n",
    "\n",
    "\n",
    "def load_job(jobname, queue_name, entity=JOB_REPO_ENTITY, project=JOB_REPO_PROJECT, tag=DOCKER_IMAGE_TAG):\n",
    "    img = jobname2img(jobname, tag)\n",
    "    wandb.termlog(f\"Creating job: {entity}/{project}/{img}\")\n",
    "    create_job(img, entity, project)\n",
    "    \n",
    "    registry = get_registry()\n",
    "    ui_name, ui_desc = registry[jobname]['name'], registry[jobname]['desc']\n",
    "    artname = jobname2artname(jobname, tag)\n",
    "    artpath = artname2artpath(artname, entity, project, tag='latest')\n",
    "    wandb.termlog(f\"Renaming job to: {ui_name}\")\n",
    "    rename_job(artpath, ui_name, ui_desc)\n",
    "    \n",
    "    new_artpath = artname2artpath(ui_name, entity, project, tag='latest')\n",
    "    wandb.termlog(\"Adding new example runs...\")\n",
    "    add_example_runs(new_artpath, jobname, entity, project, queue_name)\n",
    "\n",
    "\n",
    "def create_job(img, entity=JOB_REPO_ENTITY, project=JOB_REPO_PROJECT, env=job_repo_base_env):\n",
    "    \"\"\"\n",
    "    Create a job by running the docker image.\n",
    "    The run will show as failed because there is no config, but that's ok.  It will get deleted later.\n",
    "    \"\"\"\n",
    "    env[\"WANDB_ENTITY\"] = entity\n",
    "    env[\"WANDB_PROJECT\"] = project\n",
    "    env[\"WANDB_NAME\"] = LOADER_STR\n",
    "    env[\"WANDB_DOCKER\"] = img\n",
    "\n",
    "    client = docker.from_env()\n",
    "    \n",
    "    emulation = True\n",
    "    if emulation:\n",
    "        container = client.containers.run(img, environment=env, detach=True, auto_remove=True, network_mode='host')\n",
    "    else:\n",
    "        container = client.containers.run(img, environment=env, detach=True, auto_remove=True, network_mode='host', platform='linux/amd64')    \n",
    "    \n",
    "    output = container.attach(stdout=True, stream=True, logs=True)\n",
    "    for line in output:\n",
    "        click.echo(line.decode('utf-8'), nl=False)\n",
    "\n",
    "                    \n",
    "                    \n",
    "def rename_job(job_path, new_name, new_desc):\n",
    "    \"\"\"\n",
    "    Rename the job from the default name to a pretty name and description we define in `registry.yaml`\n",
    "    \"\"\"\n",
    "    art = api.artifact(job_path)\n",
    "    asid = art._attrs['artifactSequence']['id']\n",
    "    \n",
    "    iapi.update_artifact_collection(asid, new_name, new_desc)\n",
    "\n",
    "\n",
    "def add_example_runs(job_art_path, jobname, entity, project, queue_name):\n",
    "    \"\"\"\n",
    "    Add example runs for the user to see and easily `Clone from...` in the UI.\n",
    "    \"\"\"\n",
    "    base_launcher = partial(launch_add.launch_add, job=job_art_path, project=project, entity=entity, queue_name=queue_name)\n",
    "    config_paths = Path(f'{JOBS_DIR}/{jobname}/configs').glob('*.yml')\n",
    "    \n",
    "    for p in config_paths:\n",
    "        with p.open() as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        base_launcher(config={\"overrides\": {\"run_config\": config['config']}}, name=config['run_name'])\n",
    "        \n",
    "\n",
    "def delete_loader_runs():\n",
    "    \"\"\"\n",
    "    Delete the unsightly \"loader\" run\n",
    "    \"\"\"\n",
    "    api = wandb.Api()\n",
    "    for run in api.runs(f\"{JOB_REPO_ENTITY}/{JOB_REPO_PROJECT}\"):\n",
    "        if run.name == LOADER_STR:\n",
    "            run.delete()\n",
    "    \n",
    "\n",
    "def get_registry():\n",
    "    with open('registry.yaml') as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "def jobname2img(jobname, tag):\n",
    "    return f\"wandb/job_{jobname}:{tag}\"\n",
    "\n",
    "def get_jobnames(jobs_dir):\n",
    "    return [p.stem for p in Path(jobs_dir).glob('*')]\n",
    "\n",
    "def jobname2artname(jobname, tag):\n",
    "    return f\"job-wandb_job_{jobname}_{tag}\"\n",
    "\n",
    "def artname2artpath(artname, entity, project, tag=\"latest\"):\n",
    "    return f'{entity}/{project}/{artname}:{tag}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spin up helper resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !docker run -p 3307:3306 -d sakiladb/mysql:latest\n",
    "# !docker build -t tritonserver-wandb jobs/deploy_to_nvidia_triton/server && \\\n",
    "#     docker run --rm --net=host -p 8000:8000 -v $HOME/.aws:/root/.aws:ro -d tritonserver-wandb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Creating job: launch-test/jobs/wandb/job_openai_evals:134fcaf3d4b1499e69b426fad803b7e2cca85ab5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Thanks for trying out the Report API!\n",
      "wandb: For a tutorial, check out https://colab.research.google.com/drive/1CzyJx1nuOS4pdkXa2XPaRQyZdmFmLmXV\n",
      "wandb: \n",
      "wandb: Try out tab completion to see what's available.\n",
      "wandb:   ‚àü everything:    `wr.<tab>`\n",
      "wandb:       ‚àü panels:    `wr.panels.<tab>`\n",
      "wandb:       ‚àü blocks:    `wr.blocks.<tab>`\n",
      "wandb:       ‚àü helpers:   `wr.helpers.<tab>`\n",
      "wandb:       ‚àü templates: `wr.templates.<tab>`\n",
      "wandb:       \n",
      "wandb: For bugs/feature requests, please create an issue on github: https://github.com/wandb/wandb/issues\n",
      "wandb: Currently logged in as: megatruong (launch-test). Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.15.0\n",
      "wandb: Run data is saved locally in /launch/wandb/run-20230428_140001-wn8h49pq\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run __loader-delete-me__\n",
      "wandb: ‚≠êÔ∏è View project at https://wandb.ai/launch-test/jobs\n",
      "wandb: üöÄ View run at https://wandb.ai/launch-test/jobs/runs/wn8h49pq\n",
      "wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.\n",
      "wandb: üöÄ View run __loader-delete-me__ at: https://wandb.ai/launch-test/jobs/runs/wn8h49pq\n",
      "wandb: Synced 4 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20230428_140001-wn8h49pq/logs\n",
      "Traceback (most recent call last):\n",
      "  File \"/launch/job.py\", line 497, in <module>\n",
      "    _eval = get_correct_eval_name(run)\n",
      "  File \"/launch/job.py\", line 467, in get_correct_eval_name\n",
      "    _eval = run.config[\"eval\"]\n",
      "  File \"/usr/local/lib/python3.9/site-packages/wandb/sdk/wandb_config.py\", line 130, in __getitem__\n",
      "    return self._items[key]\n",
      "KeyError: 'eval'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Renaming job to: OpenAI Evals\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding new example runs...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m üöÄ Launching run into launch-test/jobs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Added run to queue andrew-cpu.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Launch spec:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: {'docker': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'entity': 'launch-test',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'git': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'job': 'launch-test/jobs/OpenAI Evals:latest',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'name': 'Emotional Intelligence - 01',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'overrides': {'run_config': {'eval': 'emotional-intelligence',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'model': {'name': 'gpt-3.5-turbo',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                         'override_prompt': 'You are an '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'emotionally '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'intelligent AI. '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'Select one or more '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'responses '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            '(a,b,c,d) ordered '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'by most to least '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'effective given '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'the context.'},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'oaieval_settings': {'max_samples': 10},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'registry': 'wandb/jobs/openai_evals_registry:latest'}},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'project': 'jobs',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource': 'local-container',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource_args': {'local-container': {'env-file': '/Users/andrewtruong/.wandb_launch/env.list',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'net': 'host',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'volume': ['/Users/andrewtruong/.aws:/home/andrewtruong/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.aws:/root/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.ssh:/home/andrewtruong/.ssh:ro']}}}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m üöÄ Launching run into launch-test/jobs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Added run to queue andrew-cpu.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Launch spec:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: {'docker': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'entity': 'launch-test',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'git': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'job': 'launch-test/jobs/OpenAI Evals:latest',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'name': 'Emotional Intelligence - 03',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'overrides': {'run_config': {'eval': 'emotional-intelligence',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'model': {'name': 'gpt-3.5-turbo',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                         'override_prompt': 'You are now an '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'emotionally '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'intelligent AI. In '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'this test, you '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'will be presented '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'with a few brief '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'details about an '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'emotional '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'situation, and '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'asked to choose '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'from four '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'responses the most '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'effective course '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'of action to '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'manage both the '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'emotions the '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'person is feeling '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'and the problems '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'they face in that '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'situation. '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'Although more than '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'one course of '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'action might be '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'acceptable, you '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'are asked to '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'choose what you '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'think the most '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'effective response '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'for that person in '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'that situation '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'would be. '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'Remember, you are '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'not necessarily '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'choosing what you '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'would do, or the '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'nicest thing to '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'do, but choosing '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'the most effective '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'response for that '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'situation. Select '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'one or more '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'response(s) by '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'returning the one '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'or more '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'corresponding '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'lowercase '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            \"letter(s) ('a', \"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            \"'b', 'c', or 'd'), \"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'and, if you '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'selected more than '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'one, sorting them, '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'separated by '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'hyphen, in the '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'order that you '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'think best ranks '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'them from most to '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'least effective, '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'within the context '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'of the vignette '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'provided.'},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'oaieval_settings': {'max_samples': 10},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'registry': 'wandb/jobs/openai_evals_registry:latest'}},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'project': 'jobs',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource': 'local-container',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource_args': {'local-container': {'env-file': '/Users/andrewtruong/.wandb_launch/env.list',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'net': 'host',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'volume': ['/Users/andrewtruong/.aws:/home/andrewtruong/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.aws:/root/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.ssh:/home/andrewtruong/.ssh:ro']}}}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m üöÄ Launching run into launch-test/jobs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Added run to queue andrew-cpu.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Launch spec:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: {'docker': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'entity': 'launch-test',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'git': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'job': 'launch-test/jobs/OpenAI Evals:latest',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'name': 'Emotional Intelligence - 02',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'overrides': {'run_config': {'eval': 'emotional-intelligence',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'model': {'name': 'gpt-3.5-turbo',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                         'override_prompt': 'You are a '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'therapist trying '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'to manage a '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            \"person's feelings \"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'and resolve their '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'problems. Select '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'one or more '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'responses '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            '(a,b,c,d) ordered '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'by most to least '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'effective given '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'the context.'},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'oaieval_settings': {'max_samples': 10},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'registry': 'wandb/jobs/openai_evals_registry:latest'}},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'project': 'jobs',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource': 'local-container',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource_args': {'local-container': {'env-file': '/Users/andrewtruong/.wandb_launch/env.list',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'net': 'host',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'volume': ['/Users/andrewtruong/.aws:/home/andrewtruong/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.aws:/root/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.ssh:/home/andrewtruong/.ssh:ro']}}}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m üöÄ Launching run into launch-test/jobs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Added run to queue andrew-cpu.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Launch spec:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: {'docker': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'entity': 'launch-test',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'git': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'job': 'launch-test/jobs/OpenAI Evals:latest',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'name': 'American Bar Association - 02',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'overrides': {'run_config': {'eval': 'aba_mrpc_true_false',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'model': {'name': 'gpt-3.5-turbo',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                         'override_prompt': 'You are a lawyer.  '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'Answer true or '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'false to the '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'following law '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'questions.'},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'oaieval_settings': {'max_samples': 10},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'registry': 'wandb/jobs/openai_evals_registry:latest'}},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'project': 'jobs',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource': 'local-container',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource_args': {'local-container': {'env-file': '/Users/andrewtruong/.wandb_launch/env.list',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'net': 'host',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'volume': ['/Users/andrewtruong/.aws:/home/andrewtruong/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.aws:/root/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.ssh:/home/andrewtruong/.ssh:ro']}}}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m üöÄ Launching run into launch-test/jobs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Added run to queue andrew-cpu.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Launch spec:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: {'docker': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'entity': 'launch-test',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'git': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'job': 'launch-test/jobs/OpenAI Evals:latest',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'name': 'American Bar Association - 03',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'overrides': {'run_config': {'eval': 'aba_mrpc_true_false',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'model': {'name': 'gpt-3.5-turbo',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                         'override_prompt': 'You are a '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'LawStudentGPT.  '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'Answer True or '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'False based on the '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'law.'},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'oaieval_settings': {'max_samples': 10},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'registry': 'wandb/jobs/openai_evals_registry:latest'}},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'project': 'jobs',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource': 'local-container',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource_args': {'local-container': {'env-file': '/Users/andrewtruong/.wandb_launch/env.list',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'net': 'host',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'volume': ['/Users/andrewtruong/.aws:/home/andrewtruong/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.aws:/root/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.ssh:/home/andrewtruong/.ssh:ro']}}}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m üöÄ Launching run into launch-test/jobs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Added run to queue andrew-cpu.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Launch spec:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: {'docker': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'entity': 'launch-test',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'git': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'job': 'launch-test/jobs/OpenAI Evals:latest',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'name': 'American Bar Association - 01',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'overrides': {'run_config': {'eval': 'aba_mrpc_true_false',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'model': {'name': 'gpt-3.5-turbo',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                         'override_prompt': 'You are clueless.  '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'Answer randomly!'},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'oaieval_settings': {'max_samples': 10},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'registry': 'wandb/jobs/openai_evals_registry:latest'}},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'project': 'jobs',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource': 'local-container',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource_args': {'local-container': {'env-file': '/Users/andrewtruong/.wandb_launch/env.list',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'net': 'host',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'volume': ['/Users/andrewtruong/.aws:/home/andrewtruong/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.aws:/root/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.ssh:/home/andrewtruong/.ssh:ro']}}}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m üöÄ Launching run into launch-test/jobs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Added run to queue andrew-cpu.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Launch spec:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: {'docker': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'entity': 'launch-test',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'git': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'job': 'launch-test/jobs/OpenAI Evals:latest',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'name': 'Japanese Translation - 03',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'overrides': {'run_config': {'eval': 'manga-translation-bubble',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'model': {'name': 'gpt-3.5-turbo',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                         'override_prompt': 'Imagine you are a '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'translator. Give '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'faithful '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'translations of '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'the following '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'Japanese text to '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'English. Do not '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'think out loud.'},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'oaieval_settings': {'max_samples': 10},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'registry': 'wandb/jobs/openai_evals_registry:latest'}},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'project': 'jobs',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource': 'local-container',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource_args': {'local-container': {'env-file': '/Users/andrewtruong/.wandb_launch/env.list',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'net': 'host',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'volume': ['/Users/andrewtruong/.aws:/home/andrewtruong/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.aws:/root/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.ssh:/home/andrewtruong/.ssh:ro']}}}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m üöÄ Launching run into launch-test/jobs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Added run to queue andrew-cpu.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Launch spec:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: {'docker': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'entity': 'launch-test',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'git': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'job': 'launch-test/jobs/OpenAI Evals:latest',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'name': 'Japanese Translation - 02',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'overrides': {'run_config': {'eval': 'manga-translation-bubble',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'model': {'name': 'gpt-3.5-turbo',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                         'override_prompt': 'Given a text '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'representing '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'speech of manga in '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'Japanese, generate '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'a high-quality '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'English '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'translation that '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'accurately conveys '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'the meaning and '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'emotion of the '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'original text. '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'Please do not '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'provide any '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'explanation in the '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'output other than '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'the translation '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'itself.'},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'oaieval_settings': {'max_samples': 10},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'registry': 'wandb/jobs/openai_evals_registry:latest'}},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'project': 'jobs',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource': 'local-container',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource_args': {'local-container': {'env-file': '/Users/andrewtruong/.wandb_launch/env.list',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'net': 'host',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'volume': ['/Users/andrewtruong/.aws:/home/andrewtruong/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.aws:/root/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.ssh:/home/andrewtruong/.ssh:ro']}}}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m üöÄ Launching run into launch-test/jobs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Added run to queue andrew-cpu.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Launch spec:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: {'docker': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'entity': 'launch-test',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'git': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'job': 'launch-test/jobs/OpenAI Evals:latest',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'name': 'Japanese Translation - 01',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'overrides': {'run_config': {'eval': 'manga-translation-bubble',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'model': {'name': 'gpt-3.5-turbo',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                         'override_prompt': 'You are MangaGPT. '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'You make english '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'translations of '\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                            'Japanese manga'},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'oaieval_settings': {'max_samples': 10},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'registry': 'wandb/jobs/openai_evals_registry:latest'}},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'project': 'jobs',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource': 'local-container',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource_args': {'local-container': {'env-file': '/Users/andrewtruong/.wandb_launch/env.list',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'net': 'host',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'volume': ['/Users/andrewtruong/.aws:/home/andrewtruong/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.aws:/root/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.ssh:/home/andrewtruong/.ssh:ro']}}}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Creating job: launch-test/jobs/wandb/job_gpu_optimize_with_tensor_rt:134fcaf3d4b1499e69b426fad803b7e2cca85ab5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: megatruong (launch-test). Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.15.0\n",
      "wandb: Run data is saved locally in /workspace/wandb/run-20230428_140016-l1s1aywa\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run __loader-delete-me__\n",
      "wandb: ‚≠êÔ∏è View project at https://wandb.ai/launch-test/jobs\n",
      "wandb: üöÄ View run at https://wandb.ai/launch-test/jobs/runs/l1s1aywa\n",
      "wandb: downloading model\n",
      "wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.\n",
      "wandb: üöÄ View run __loader-delete-me__ at: https://wandb.ai/launch-test/jobs/runs/l1s1aywa\n",
      "wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20230428_140016-l1s1aywa/logs\n",
      "Traceback (most recent call last):\n",
      "  File \"job.py\", line 27, in <module>\n",
      "    model_dir = run.config[\"model\"].download()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/wandb/sdk/wandb_config.py\", line 130, in __getitem__\n",
      "    return self._items[key]\n",
      "KeyError: 'model'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Renaming job to: Optimize with NVIDIA TensorRT\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding new example runs...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m üöÄ Launching run into launch-test/jobs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Added run to queue andrew-gpu.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Launch spec:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: {'docker': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'entity': 'launch-test',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'git': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'job': 'launch-test/jobs/Optimize with NVIDIA TensorRT:latest',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'name': 'TensorFlow',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'overrides': {'run_config': {'benchmark': {'benchmarking_rounds': 1000,\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                             'input_shape': [32, 299, 299, 3],\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                             'warmup_rounds': 50},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'model': 'wandb-artifact://megatruong/trt-testing/inceptionv3:latest',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'precision': 'FP32'}},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'project': 'jobs',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource': 'local-container',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource_args': {'local-container': {'env-file': '/Users/andrewtruong/.wandb_launch/env.list',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'net': 'host',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'volume': ['/Users/andrewtruong/.aws:/home/andrewtruong/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.aws:/root/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.ssh:/home/andrewtruong/.ssh:ro']}}}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Creating job: launch-test/jobs/wandb/job_hello_world:134fcaf3d4b1499e69b426fad803b7e2cca85ab5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: megatruong (launch-test). Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.15.0\n",
      "wandb: Run data is saved locally in /launch/wandb/run-20230428_140026-uovsuji6\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run __loader-delete-me__\n",
      "wandb: ‚≠êÔ∏è View project at https://wandb.ai/launch-test/jobs\n",
      "wandb: üöÄ View run at https://wandb.ai/launch-test/jobs/runs/uovsuji6\n",
      "wandb: Waiting for W&B process to finish... (success).\n",
      "wandb: \n",
      "wandb: Run summary:\n",
      "wandb: hello world\n",
      "wandb: \n",
      "wandb: üöÄ View run __loader-delete-me__ at: https://wandb.ai/launch-test/jobs/runs/uovsuji6\n",
      "wandb: Synced 4 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20230428_140026-uovsuji6/logs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Renaming job to: Hello World\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding new example runs...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m üöÄ Launching run into launch-test/jobs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Added run to queue andrew-cpu.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Launch spec:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: {'docker': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'entity': 'launch-test',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'git': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'job': 'launch-test/jobs/Hello World:latest',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'name': 'Hello World Example',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'overrides': {'run_config': {}},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'project': 'jobs',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource': 'local-container',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource_args': {'local-container': {'env-file': '/Users/andrewtruong/.wandb_launch/env.list',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'net': 'host',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'volume': ['/Users/andrewtruong/.aws:/home/andrewtruong/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.aws:/root/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.ssh:/home/andrewtruong/.ssh:ro']}}}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Creating job: launch-test/jobs/wandb/job_deploy_to_sagemaker_endpoints:134fcaf3d4b1499e69b426fad803b7e2cca85ab5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: megatruong (launch-test). Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.15.0\n",
      "wandb: Run data is saved locally in /launch/wandb/run-20230428_140044-80629u0m\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run __loader-delete-me__\n",
      "wandb: ‚≠êÔ∏è View project at https://wandb.ai/launch-test/jobs\n",
      "wandb: üöÄ View run at https://wandb.ai/launch-test/jobs/runs/80629u0m\n",
      "wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.\n",
      "wandb: üöÄ View run __loader-delete-me__ at: https://wandb.ai/launch-test/jobs/runs/80629u0m\n",
      "wandb: Synced 4 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20230428_140044-80629u0m/logs\n",
      "Traceback (most recent call last):\n",
      "  File \"/launch/job.py\", line 47, in <module>\n",
      "    if run.config[\"framework\"] not in supported_frameworks:\n",
      "  File \"/usr/local/lib/python3.9/site-packages/wandb/sdk/wandb_config.py\", line 130, in __getitem__\n",
      "    return self._items[key]\n",
      "KeyError: 'framework'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Renaming job to: Deploy to Sagemaker Endpoints\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding new example runs...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m üöÄ Launching run into launch-test/jobs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Added run to queue andrew-cpu.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Launch spec:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: {'docker': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'entity': 'launch-test',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'git': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'job': 'launch-test/jobs/Deploy to Sagemaker Endpoints:latest',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'name': 'Deploy PyTorch Model',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'overrides': {'run_config': {'artifact': 'wandb-artifact://megatruong/ptl-testing2/model-vgw632i7:v0',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'framework': 'pytorch',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'framework_version': '1.12',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'instance_count': 1,\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'instance_type': 'ml.c5.xlarge',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'python_version': 'py38',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'sagemaker_bucket': 'sagemaker-us-west-2-687678353814',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'sagemaker_model_deployment_kwargs': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'sagemaker_model_setup_kwargs': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'sagemaker_role': 'arn:aws:iam::687678353814:role/sagemaker'}},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'project': 'jobs',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource': 'local-container',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource_args': {'local-container': {'env-file': '/Users/andrewtruong/.wandb_launch/env.list',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'net': 'host',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'volume': ['/Users/andrewtruong/.aws:/home/andrewtruong/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.aws:/root/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.ssh:/home/andrewtruong/.ssh:ro']}}}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m üöÄ Launching run into launch-test/jobs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Added run to queue andrew-cpu.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Launch spec:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: {'docker': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'entity': 'launch-test',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'git': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'job': 'launch-test/jobs/Deploy to Sagemaker Endpoints:latest',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'name': 'Deploy TensorFlow Model',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'overrides': {'run_config': {'artifact': 'wandb-artifact://megatruong/fashion-mnist-keras-triton/model-sage-feather-1:v2',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'framework': 'tensorflow',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'framework_version': '2.10.0',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'instance_count': 1,\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'instance_type': 'ml.c5.xlarge',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'python_version': 'py38',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'sagemaker_bucket': 'sagemaker-us-west-2-687678353814',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'sagemaker_model_deployment_kwargs': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'sagemaker_model_setup_kwargs': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'sagemaker_role': 'arn:aws:iam::687678353814:role/sagemaker'}},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'project': 'jobs',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource': 'local-container',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource_args': {'local-container': {'env-file': '/Users/andrewtruong/.wandb_launch/env.list',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'net': 'host',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'volume': ['/Users/andrewtruong/.aws:/home/andrewtruong/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.aws:/root/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.ssh:/home/andrewtruong/.ssh:ro']}}}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Creating job: launch-test/jobs/wandb/job_msft_teams_webhook:134fcaf3d4b1499e69b426fad803b7e2cca85ab5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: megatruong (launch-test). Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.15.0\n",
      "wandb: Run data is saved locally in /launch/wandb/run-20230428_140053-e5svo2zj\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run __loader-delete-me__\n",
      "wandb: ‚≠êÔ∏è View project at https://wandb.ai/launch-test/jobs\n",
      "wandb: üöÄ View run at https://wandb.ai/launch-test/jobs/runs/e5svo2zj\n",
      "wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.\n",
      "wandb: üöÄ View run __loader-delete-me__ at: https://wandb.ai/launch-test/jobs/runs/e5svo2zj\n",
      "wandb: Synced 4 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20230428_140053-e5svo2zj/logs\n",
      "Traceback (most recent call last):\n",
      "  File \"/launch/job.py\", line 12, in <module>\n",
      "    msg = pymsteams.connectorcard(run.config[\"webhook_url\"])\n",
      "  File \"/usr/local/lib/python3.9/site-packages/wandb/sdk/wandb_config.py\", line 130, in __getitem__\n",
      "    return self._items[key]\n",
      "KeyError: 'webhook_url'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Renaming job to: Microsoft Teams Webhook\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding new example runs...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m üöÄ Launching run into launch-test/jobs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Added run to queue andrew-cpu.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Launch spec:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: {'docker': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'entity': 'launch-test',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'git': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'job': 'launch-test/jobs/Microsoft Teams Webhook:latest',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'name': 'Example',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'overrides': {'run_config': {'alias': '${alias}',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'artifact': 'wandb-artifact://wandb/pytorch-lightning-e2e/nature-e1d5dg6m:latest',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'color': '#00FF00',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'link_button': {'text': 'Review Deployed Model',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                               'url': 'https://www.wandb.ai'},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'retry_settings': {'attempts': 3,\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                  'backoff': {'max': 60,\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                              'multiplier': 1}},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'text': 'example text',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'title': 'New model deployed!',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'webhook_url': 'https://sysadminwandb.webhook.office.com/webhookb2/1fc24ff9-fe1f-4cf2-ab3b-88d0189149fd@af722783-84b6-4adc-9c49-c792786eab4a/IncomingWebhook/11767fa7c40840e4bb52817bce8d59aa/44f0d0e4-adc1-4ca6-84bc-1768a8278b1f'}},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'project': 'jobs',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource': 'local-container',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource_args': {'local-container': {'env-file': '/Users/andrewtruong/.wandb_launch/env.list',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'net': 'host',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'volume': ['/Users/andrewtruong/.aws:/home/andrewtruong/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.aws:/root/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.ssh:/home/andrewtruong/.ssh:ro']}}}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Creating job: launch-test/jobs/wandb/job_http_webhook:134fcaf3d4b1499e69b426fad803b7e2cca85ab5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: megatruong (launch-test). Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.15.0\n",
      "wandb: Run data is saved locally in /launch/wandb/run-20230428_140102-1c5nvg85\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run __loader-delete-me__\n",
      "wandb: ‚≠êÔ∏è View project at https://wandb.ai/launch-test/jobs\n",
      "wandb: üöÄ View run at https://wandb.ai/launch-test/jobs/runs/1c5nvg85\n",
      "wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.\n",
      "wandb: üöÄ View run __loader-delete-me__ at: https://wandb.ai/launch-test/jobs/runs/1c5nvg85\n",
      "wandb: Synced 4 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20230428_140102-1c5nvg85/logs\n",
      "Traceback (most recent call last):\n",
      "  File \"/launch/job.py\", line 24, in <module>\n",
      "    token = os.getenv(run.config['github_api_token_env_var'])\n",
      "  File \"/usr/local/lib/python3.9/site-packages/wandb/sdk/wandb_config.py\", line 130, in __getitem__\n",
      "    return self._items[key]\n",
      "KeyError: 'github_api_token_env_var'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Renaming job to: Send Webhook\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding new example runs...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m üöÄ Launching run into launch-test/jobs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Added run to queue andrew-cpu.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Launch spec:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: {'docker': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'entity': 'launch-test',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'git': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'job': 'launch-test/jobs/Send Webhook:latest',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'name': 'Example',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'overrides': {'run_config': {'github_api_token_env_var': 'GITHUB_API_TOKEN',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'payload_inputs': {'template-file': 'workflow_helpers/template.py'},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'ref': 'main',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'repo': 'wandb/launch-jobs',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'retry_settings': {'attempts': 3,\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                  'backoff': {'max': 60,\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                              'multiplier': 1}},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'workflow': 'generate-report.yml'}},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'project': 'jobs',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource': 'local-container',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource_args': {'local-container': {'env-file': '/Users/andrewtruong/.wandb_launch/env.list',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'net': 'host',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'volume': ['/Users/andrewtruong/.aws:/home/andrewtruong/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.aws:/root/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.ssh:/home/andrewtruong/.ssh:ro']}}}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Creating job: launch-test/jobs/wandb/job_github_actions_workflow_dispatch:134fcaf3d4b1499e69b426fad803b7e2cca85ab5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: megatruong (launch-test). Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.15.0\n",
      "wandb: Run data is saved locally in /launch/wandb/run-20230428_140112-vdo01emq\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run __loader-delete-me__\n",
      "wandb: ‚≠êÔ∏è View project at https://wandb.ai/launch-test/jobs\n",
      "wandb: üöÄ View run at https://wandb.ai/launch-test/jobs/runs/vdo01emq\n",
      "wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.\n",
      "wandb: üöÄ View run __loader-delete-me__ at: https://wandb.ai/launch-test/jobs/runs/vdo01emq\n",
      "wandb: Synced 4 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20230428_140112-vdo01emq/logs\n",
      "Traceback (most recent call last):\n",
      "  File \"/launch/job.py\", line 23, in <module>\n",
      "    token = os.getenv(run.config[\"github_api_token_env_var\"])\n",
      "  File \"/usr/local/lib/python3.9/site-packages/wandb/sdk/wandb_config.py\", line 130, in __getitem__\n",
      "    return self._items[key]\n",
      "KeyError: 'github_api_token_env_var'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Renaming job to: Github Actions Workflow Dispatch\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding new example runs...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m üöÄ Launching run into launch-test/jobs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Added run to queue andrew-cpu.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Launch spec:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: {'docker': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'entity': 'launch-test',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'git': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'job': 'launch-test/jobs/Github Actions Workflow Dispatch:latest',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'name': 'Generate Report Action',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'overrides': {'run_config': {'github_api_token_env_var': 'GITHUB_API_TOKEN',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'owner': 'wandb',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'ref': 'main',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'repo': 'launch-jobs',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'retry_settings': {'attempts': 3,\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                  'backoff': {'max': 60,\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                              'multiplier': 1}},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'workflow': 'generate-report.yml',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'workflow_inputs': {'template-file': 'workflow_helpers/template.py'}}},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'project': 'jobs',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource': 'local-container',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource_args': {'local-container': {'env-file': '/Users/andrewtruong/.wandb_launch/env.list',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'net': 'host',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'volume': ['/Users/andrewtruong/.aws:/home/andrewtruong/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.aws:/root/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.ssh:/home/andrewtruong/.ssh:ro']}}}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Creating job: launch-test/jobs/wandb/job_deploy_to_nvidia_triton:134fcaf3d4b1499e69b426fad803b7e2cca85ab5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: megatruong (launch-test). Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.15.0\n",
      "wandb: Run data is saved locally in /launch/wandb/run-20230428_140130-amzh0ase\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run __loader-delete-me__\n",
      "wandb: ‚≠êÔ∏è View project at https://wandb.ai/launch-test/jobs\n",
      "wandb: üöÄ View run at https://wandb.ai/launch-test/jobs/runs/amzh0ase\n",
      "wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.\n",
      "wandb: Network error (TransientError), entering retry loop.\n",
      "wandb: üöÄ View run __loader-delete-me__ at: https://wandb.ai/launch-test/jobs/runs/amzh0ase\n",
      "wandb: Synced 4 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20230428_140130-amzh0ase/logs\n",
      "Traceback (most recent call last):\n",
      "  File \"/launch/job.py\", line 79, in <module>\n",
      "    model_name, model_ver = run.config[\"artifact\"].name.split(\":v\")\n",
      "  File \"/usr/local/lib/python3.9/site-packages/wandb/sdk/wandb_config.py\", line 130, in __getitem__\n",
      "    return self._items[key]\n",
      "KeyError: 'artifact'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Renaming job to: Deploy to NVIDIA Triton Inference Server\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding new example runs...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m üöÄ Launching run into launch-test/jobs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Added run to queue andrew-cpu.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Launch spec:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: {'docker': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'entity': 'launch-test',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'git': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'job': 'launch-test/jobs/Deploy to NVIDIA Triton Inference Server:latest',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'name': 'Deploy PyTorch Model',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'overrides': {'run_config': {'artifact': 'wandb-artifact://megatruong/ptl-testing2/my_model:v0',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'framework': 'pytorch',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'triton_bucket': 'andrew-triton-bucket',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'triton_model_config_overrides': {'input': [{'data_type': 'TYPE_FP32',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                            'dims': [3,\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                     28,\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                     28],\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                            'name': 'conv1'}],\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                 'max_batch_size': 32,\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                 'output': [{'data_type': 'TYPE_FP32',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                             'dims': [1],\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                             'name': 'fc'}]},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'triton_model_repo_path': 'models',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'triton_url': 'localhost:8000'}},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'project': 'jobs',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource': 'local-container',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource_args': {'local-container': {'env-file': '/Users/andrewtruong/.wandb_launch/env.list',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'net': 'host',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'volume': ['/Users/andrewtruong/.aws:/home/andrewtruong/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.aws:/root/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.ssh:/home/andrewtruong/.ssh:ro']}}}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m üöÄ Launching run into launch-test/jobs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Added run to queue andrew-cpu.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[35mlaunch:\u001b[0m Launch spec:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: {'docker': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'entity': 'launch-test',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'git': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'job': 'launch-test/jobs/Deploy to NVIDIA Triton Inference Server:latest',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'name': 'Deploy TensorFlow Model',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'overrides': {'run_config': {'artifact': 'wandb-artifact://megatruong/fashion-mnist-keras-triton/model-sage-feather-1:v3',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'framework': 'tensorflow',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'triton_bucket': 'andrew-triton-bucket',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'triton_model_config_overrides': {},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'triton_model_repo_path': 'models',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                               'triton_url': 'localhost:8000'}},\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'project': 'jobs',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource': 'local-container',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  'resource_args': {'local-container': {'env-file': '/Users/andrewtruong/.wandb_launch/env.list',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'net': 'host',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                        'volume': ['/Users/andrewtruong/.aws:/home/andrewtruong/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.aws:/root/.aws:ro',\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                   '/Users/andrewtruong/.ssh:/home/andrewtruong/.ssh:ro']}}}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "jobnames = get_jobnames(JOBS_DIR)\n",
    "is_m1 = platform.machine() == 'arm64' and platform.system() == \"Darwin\"\n",
    "\n",
    "for jobname in jobnames:\n",
    "    if is_m1 and jobname == 'sql_query':\n",
    "        continue  # connectorx seems to cause issues with emulation on M1.\n",
    "    if jobname.startswith('gpu_'):\n",
    "        load_job(jobname, GPU_QUEUE_NAME)\n",
    "    else:\n",
    "        load_job(jobname, CPU_QUEUE_NAME)\n",
    "\n",
    "delete_loader_runs()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete sagemaker endpoints that were spun up\n",
    "- You may have to run this manually because the jobs above need to actually run before the endpoints are created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "sagemaker = boto3.client('sagemaker')\n",
    "\n",
    "response = sagemaker.list_endpoints()\n",
    "endpoints = response['Endpoints']\n",
    "\n",
    "for endpoint in endpoints:\n",
    "    try:\n",
    "        sagemaker.delete_endpoint(EndpointName=endpoint['EndpointName'])\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check to see if any setup runs failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploy to NVIDIA Triton Inference Server:v0::Deploy TensorFlow Model || <Run megatruong/jobs/7qmjh103 (failed)>\n",
      "Deploy to NVIDIA Triton Inference Server:v0::Deploy PyTorch Model || <Run megatruong/jobs/uo07ijwp (failed)>\n",
      "Github Actions Workflow Dispatch:v0::Generate Report Action || <Run megatruong/jobs/ntic18z3 (failed)>\n",
      "job-wandb_job_optimize_with_tensor_rt_98f24741ebd810806def11fc2499236274147f50:v0::TensorFlow || <Run megatruong/jobs/bfufwq23 (failed)>\n",
      "Send Webhook:v0::Example || <Run megatruong/jobs/bdfeudxn (failed)>\n",
      "SQL Query (table):v0::Table || <Run megatruong/jobs/wzpzwyuk (failed)>\n",
      "SQL Query (artifact):v0::Artifact || <Run megatruong/jobs/h7bntbjl (failed)>\n",
      "OpenAI Evals:v0::American Bar Association - 03 || <Run megatruong/jobs/vo54r7mj (failed)>\n",
      "job-wandb_job_deploy_to_nvidia_triton_98f24741ebd810806def11fc2499236274147f50:v0::good-violet-143 || <Run megatruong/jobs/020ch8b4 (failed)>\n",
      "job-wandb_job_github_actions_workflow_dispatch_98f24741ebd810806def11fc2499236274147f50:v0::misunderstood-aardvark-142 || <Run megatruong/jobs/0kn2pmj8 (failed)>\n",
      "job-wandb_job_optimize_with_tensor_rt_98f24741ebd810806def11fc2499236274147f50:v1::quiet-tree-141 || <Run megatruong/jobs/u45nnkw8 (failed)>\n",
      "job-wandb_job_http_webhook_98f24741ebd810806def11fc2499236274147f50:v0::peachy-haze-140 || <Run megatruong/jobs/hcbvux7c (failed)>\n",
      "job-wandb_job_sql_query_table_98f24741ebd810806def11fc2499236274147f50:v0::playful-bush-138 || <Run megatruong/jobs/zgxe1pk5 (failed)>\n",
      "job-wandb_job_deploy_to_sagemaker_endpoints_98f24741ebd810806def11fc2499236274147f50:v0::super-bush-137 || <Run megatruong/jobs/mdngd0zb (failed)>\n",
      "job-wandb_job_sql_query_artifact_98f24741ebd810806def11fc2499236274147f50:v0::golden-bird-136 || <Run megatruong/jobs/lxiucj2v (failed)>\n",
      "job-wandb_job_sql_query_artifact_98f24741ebd810806def11fc2499236274147f50:v0::scarlet-universe-133 || <Run megatruong/jobs/x1dhmz0l (failed)>\n",
      "Deploy to NVIDIA Triton Inference Server:v0::TensorFlow Model || <Run megatruong/jobs/dwepoj36 (failed)>\n",
      "Deploy to NVIDIA Triton Inference Server:v0::PyTorch Model || <Run megatruong/jobs/f1q2ps40 (failed)>\n",
      "Github Actions Workflow Dispatch:v0::Github Actions Workflow Dispatch || <Run megatruong/jobs/wt8cteg0 (failed)>\n",
      "job-wandb_job_optimize_with_tensor_rt_98f24741ebd810806def11fc2499236274147f50:v0::Optimize with NVIDIA TensorRT - Tensorflow || <Run megatruong/jobs/5n1bugbj (failed)>\n",
      "Send Webhook:v0::HTTP Webhook Example || <Run megatruong/jobs/terolwvq (failed)>\n",
      "SQL Query (table):v0::Table || <Run megatruong/jobs/e4qqh30t (failed)>\n",
      "SQL Query (artifact):v0::Artifact || <Run megatruong/jobs/q0bbhjlg (failed)>\n",
      "Deploy to NVIDIA Triton Inference Server:v0::testing_run_name || <Run megatruong/jobs/gvjh6qlf (failed)>\n",
      "Deploy to NVIDIA Triton Inference Server:v0::testing_name || <Run megatruong/jobs/k356hnwq (failed)>\n",
      "Deploy to NVIDIA Triton Inference Server:v0::northern-surf-113 || <Run megatruong/jobs/impjdg9s (failed)>\n",
      "Deploy to NVIDIA Triton Inference Server:v0::fragrant-sun-112 || <Run megatruong/jobs/a9lk7exn (failed)>\n",
      "Deploy to NVIDIA Triton Inference Server:v0::floral-vortex-111 || <Run megatruong/jobs/s8v3qa0e (failed)>\n",
      "Github Actions Workflow Dispatch:v0::feasible-elevator-110 || <Run megatruong/jobs/1h67bji1 (failed)>\n",
      "Optimize with NVIDIA TensorRT:v0::worldly-voice-109 || <Run megatruong/jobs/zjybn6d9 (failed)>\n",
      "Send Webhook:v0::twilight-silence-108 || <Run megatruong/jobs/8oka3z3m (failed)>\n",
      "SQL Query (table):v0::cosmic-night-106 || <Run megatruong/jobs/9ob3lsda (failed)>\n",
      "Deploy to Sagemaker Endpoints:v0::whole-lake-105 || <Run megatruong/jobs/peanq8w6 (failed)>\n",
      "SQL Query (artifact):v0::legendary-snowball-104 || <Run megatruong/jobs/54s8v83k (failed)>\n",
      "SQL Query (artifact):v0::fallen-flower-90 || <Run megatruong/jobs/q5ag8fe6 (failed)>\n",
      "SQL Query (artifact):v0::apricot-lion-88 || <Run megatruong/jobs/6y0uxzr3 (failed)>\n",
      "SQL Query (artifact):v0::visionary-resonance-86 || <Run megatruong/jobs/nm4ss47j (failed)>\n",
      "SQL Query (artifact):v0::summer-sun-83 || <Run megatruong/jobs/wg46193e (failed)>\n",
      "SQL Query (artifact):v0::wild-deluge-81 || <Run megatruong/jobs/bpxtz55w (failed)>\n",
      "SQL Query (artifact):v0::ancient-lake-75 || <Run megatruong/jobs/na1shvs2 (failed)>\n",
      "SQL Query (artifact):v0::dauntless-elevator-73 || <Run megatruong/jobs/lrm47x3v (failed)>\n",
      "SQL Query (artifact):v0::autumn-butterfly-70 || <Run megatruong/jobs/dwspbjeg (failed)>\n",
      "SQL Query (artifact):v0::effortless-mountain-67 || <Run megatruong/jobs/8knqiqhm (failed)>\n",
      "SQL Query (artifact):v0::fallen-sun-66 || <Run megatruong/jobs/j0vb083l (failed)>\n",
      "SQL Query (artifact):v0::solar-tree-65 || <Run megatruong/jobs/mpzvsc2d (failed)>\n",
      "SQL Query (artifact):v0::fancy-tree-64 || <Run megatruong/jobs/vovgsu5m (failed)>\n",
      "SQL Query (artifact):v0::stoic-wave-63 || <Run megatruong/jobs/6of9sfb5 (failed)>\n",
      "SQL Query (artifact):v0::neat-bird-62 || <Run megatruong/jobs/ywlojur8 (failed)>\n",
      "SQL Query (artifact):v0::earthy-haze-61 || <Run megatruong/jobs/beav73ec (failed)>\n",
      "SQL Query (artifact):v0::eager-water-60 || <Run megatruong/jobs/g53kgs4i (failed)>\n",
      "SQL Query (artifact):v0::stellar-yogurt-59 || <Run megatruong/jobs/v0l1i90e (failed)>\n",
      "SQL Query (artifact):v0::light-waterfall-56 || <Run megatruong/jobs/qlqg177x (failed)>\n",
      "SQL Query (artifact):v0::comic-silence-55 || <Run megatruong/jobs/dp86xott (failed)>\n",
      "SQL Query (artifact):v0::upbeat-water-50 || <Run megatruong/jobs/ef0oeljw (failed)>\n",
      "job-itsandrewtruong_sql_query_table_latest:v1::solar-plasma-41 || <Run megatruong/jobs/87i1gtqc (failed)>\n",
      "job-itsandrewtruong_sql_query_artifact_latest:v1::comfy-snowflake-40 || <Run megatruong/jobs/4ir4hgz9 (failed)>\n",
      "job-itsandrewtruong_optimize_with_tensor_rt_latest:v0::dry-terrain-39 || <Run megatruong/jobs/vmuse92c (failed)>\n",
      "job-itsandrewtruong_sql_query_table_latest:v0::easy-silence-31 || <Run megatruong/jobs/hfzlq1e1 (failed)>\n",
      "job-itsandrewtruong_sql_query_artifact_latest:v0::colorful-silence-30 || <Run megatruong/jobs/h5ipr1f4 (failed)>\n",
      "job-itsandrewtruong_optimize_with_tensor_rt_latest:v0::rose-feather-29 || <Run megatruong/jobs/9sze32sl (failed)>\n",
      "job-itsandrewtruong_sql_query_table_latest:v0::ethereal-wood-17 || <Run megatruong/jobs/uddzfsag (failed)>\n",
      "job-itsandrewtruong_sql_query_artifact_latest:v0::breezy-voice-16 || <Run megatruong/jobs/zxofxifz (failed)>\n",
      "job-itsandrewtruong_optimize_with_tensor_rt_latest:v0::denim-bee-15 || <Run megatruong/jobs/brjjj7lq (failed)>\n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()  # you need to run this again to refresh the runs\n",
    "for run in api.runs(f\"{JOB_REPO_ENTITY}/{JOB_REPO_PROJECT}\"):\n",
    "    if run.state == 'failed':\n",
    "        for art in run.used_artifacts():\n",
    "            if art.type == 'job':\n",
    "                job = art.name\n",
    "                break\n",
    "        print(f\"{job}::{run.name} || {run}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
