# syntax=docker/dockerfile:1.4

# NOTE: You will need to have access to the the private repo
FROM nvcr.io/ohlfw0olaadg/ea-participants/nemollm-inference-ms:24.01

WORKDIR /launch
COPY --link requirements.txt ./

USER root
RUN apt update
RUN apt install -y python3-pip python3-setuptools
RUN python3 -m pip install --upgrade pip setuptools wheel
RUN pip3 install -r requirements.txt

# Where the llama configs live
COPY --link trt_llm_configs/ trt_llm_configs/

# Example configs for different deployments
COPY --link job.py configs/ ./

USER nemo
ENTRYPOINT ["python3", "job.py"]
