{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'img1.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m client \u001b[39m=\u001b[39m grpcclient\u001b[39m.\u001b[39mInferenceServerClient(url\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlocalhost:8001\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m image_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mfromfile(\u001b[39m\"\u001b[39;49m\u001b[39mimg1.jpg\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39muint8\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      7\u001b[0m image_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpand_dims(image_data, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      9\u001b[0m input_tensors \u001b[39m=\u001b[39m [grpcclient\u001b[39m.\u001b[39mInferInput(\u001b[39m\"\u001b[39m\u001b[39minput_image\u001b[39m\u001b[39m\"\u001b[39m, image_data\u001b[39m.\u001b[39mshape, \u001b[39m\"\u001b[39m\u001b[39mUINT8\u001b[39m\u001b[39m\"\u001b[39m)]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'img1.jpg'"
     ]
    }
   ],
   "source": [
    "import tritonclient.grpc as grpcclient\n",
    "import numpy as np\n",
    "\n",
    "client = grpcclient.InferenceServerClient(url=\"localhost:8001\")\n",
    "\n",
    "image_data = np.fromfile(\"img1.jpg\", dtype=\"uint8\")\n",
    "image_data = np.expand_dims(image_data, axis=0)\n",
    "\n",
    "input_tensors = [grpcclient.InferInput(\"input_image\", image_data.shape, \"UINT8\")]\n",
    "input_tensors[0].set_data_from_numpy(image_data)\n",
    "results = client.infer(model_name=\"ensemble_model\", inputs=input_tensors)\n",
    "output_data = results.as_numpy(\"recognized_text\").astype(str)\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "InferenceServerException",
     "evalue": "[StatusCode.INVALID_ARGUMENT] [request id: <id_unknown>] inference request batch-size must be <= 256 for 'ensemble_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInferenceServerException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m input_tensors \u001b[39m=\u001b[39m [grpcclient\u001b[39m.\u001b[39mInferInput(\u001b[39m\"\u001b[39m\u001b[39minput_image\u001b[39m\u001b[39m\"\u001b[39m, img\u001b[39m.\u001b[39mshape, \u001b[39m\"\u001b[39m\u001b[39mUINT8\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[1;32m     19\u001b[0m input_tensors[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mset_data_from_numpy(img)\n\u001b[0;32m---> 20\u001b[0m results \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49minfer(model_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mensemble_model\u001b[39;49m\u001b[39m\"\u001b[39;49m, inputs\u001b[39m=\u001b[39;49minput_tensors)\n\u001b[1;32m     21\u001b[0m output_data \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39mas_numpy(\u001b[39m\"\u001b[39m\u001b[39mrecognized_text\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[39mprint\u001b[39m(output_data)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pylaunch39/lib/python3.9/site-packages/tritonclient/grpc/__init__.py:1469\u001b[0m, in \u001b[0;36mInferenceServerClient.infer\u001b[0;34m(self, model_name, inputs, model_version, outputs, request_id, sequence_id, sequence_start, sequence_end, priority, timeout, client_timeout, headers, compression_algorithm, parameters)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m   1468\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m rpc_error:\n\u001b[0;32m-> 1469\u001b[0m     raise_error_grpc(rpc_error)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pylaunch39/lib/python3.9/site-packages/tritonclient/grpc/__init__.py:75\u001b[0m, in \u001b[0;36mraise_error_grpc\u001b[0;34m(rpc_error)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_error_grpc\u001b[39m(rpc_error):\n\u001b[0;32m---> 75\u001b[0m     \u001b[39mraise\u001b[39;00m get_error_grpc(rpc_error) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mInferenceServerException\u001b[0m: [StatusCode.INVALID_ARGUMENT] [request id: <id_unknown>] inference request batch-size must be <= 256 for 'ensemble_model'"
     ]
    }
   ],
   "source": [
    "# import tritonclient.grpc as grpcclient\n",
    "# import tritonclient.http as httpclient\n",
    "# import numpy as np\n",
    "# import httpx\n",
    "# from PIL import Image\n",
    "# from io import BytesIO\n",
    "\n",
    "# client = grpcclient.InferenceServerClient(url=\"localhost:8001\")\n",
    "# # client = httpclient.InferenceServerClient(url='localhost:8000')\n",
    "# # client.is_server_live()\n",
    "\n",
    "# url = 'https://literacyideas.com/wp-content/uploads/2021/08/2_different_text_types-1024x768.png'\n",
    "# r = httpx.get(url)\n",
    "# img = Image.open(BytesIO(r.content))\n",
    "# img = np.array(img)\n",
    "# # img = np.expand_dims(img, axis=0)\n",
    "\n",
    "# input_tensors = [grpcclient.InferInput(\"input_image\", img.shape, \"UINT8\")]\n",
    "# input_tensors[0].set_data_from_numpy(img)\n",
    "# results = client.infer(model_name=\"ensemble_model\", inputs=input_tensors)\n",
    "# output_data = results.as_numpy(\"recognized_text\").astype(str)\n",
    "# print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 1024)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylaunch39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
