{
  "type": "object",
  "properties": {
    "tasks": {
      "type": "array",
      "title": "Evaluations",
      "description": "Select the tasks to run. For more information on the tasks, see the docs at: https://inspect.aisi.org.uk/evals/.",
      "minItems": 1,
      "maxItems": 4,
      "items": {
        "type": "string",
        "enum": [
          "inspect_evals/agent_bench_os",
          "inspect_evals/agentharm",
          "inspect_evals/agentharm_benign",
          "inspect_evals/agentic_misalignment",
          "inspect_evals/agie_aqua_rat",
          "inspect_evals/agie_logiqa_en",
          "inspect_evals/agie_lsat_ar",
          "inspect_evals/agie_lsat_lr",
          "inspect_evals/agie_lsat_rc",
          "inspect_evals/agie_math",
          "inspect_evals/agie_sat_en",
          "inspect_evals/agie_sat_en_without_passage",
          "inspect_evals/agie_sat_math",
          "inspect_evals/aime2024",
          "inspect_evals/air_bench",
          "inspect_evals/arc_challenge",
          "inspect_evals/arc_easy",
          "inspect_evals/bbeh",
          "inspect_evals/bbeh_mini",
          "inspect_evals/bbh",
          "inspect_evals/bbq",
          "inspect_evals/boolq",
          "inspect_evals/chembench",
          "inspect_evals/commonsense_qa",
          "inspect_evals/cyse3_visual_prompt_injection",
          "inspect_evals/drop",
          "inspect_evals/gpqa_diamond",
          "inspect_evals/gsm8k",
          "inspect_evals/healthbench",
          "inspect_evals/healthbench_consensus",
          "inspect_evals/healthbench_hard",
          "inspect_evals/hellaswag",
          "inspect_evals/hle",
          "inspect_evals/ifeval",
          "inspect_evals/infinite_bench_code_debug",
          "inspect_evals/infinite_bench_code_run",
          "inspect_evals/infinite_bench_kv_retrieval",
          "inspect_evals/infinite_bench_longbook_choice_eng",
          "inspect_evals/infinite_bench_longdialogue_qa_eng",
          "inspect_evals/infinite_bench_math_calc",
          "inspect_evals/infinite_bench_math_find",
          "inspect_evals/infinite_bench_number_string",
          "inspect_evals/infinite_bench_passkey",
          "inspect_evals/lab_bench_cloning_scenarios",
          "inspect_evals/lab_bench_dbqa",
          "inspect_evals/lab_bench_figqa",
          "inspect_evals/lab_bench_litqa",
          "inspect_evals/lab_bench_protocolqa",
          "inspect_evals/lab_bench_seqqa",
          "inspect_evals/lab_bench_suppqa",
          "inspect_evals/lab_bench_tableqa",
          "inspect_evals/lingoly",
          "inspect_evals/lingoly_too",
          "inspect_evals/mask",
          "inspect_evals/math",
          "inspect_evals/medqa",
          "inspect_evals/mgsm",
          "inspect_evals/mmiu",
          "inspect_evals/mmlu_0_shot",
          "inspect_evals/mmlu_5_shot",
          "inspect_evals/mmlu_pro",
          "inspect_evals/mmmu_multiple_choice",
          "inspect_evals/mmmu_open",
          "inspect_evals/musr",
          "inspect_evals/niah",
          "inspect_evals/onet_m6",
          "inspect_evals/paws",
          "inspect_evals/personality_BFI",
          "inspect_evals/personality_TRAIT",
          "inspect_evals/piqa",
          "inspect_evals/pre_flight",
          "inspect_evals/pubmedqa",
          "inspect_evals/race_h",
          "inspect_evals/sec_qa_v1",
          "inspect_evals/sec_qa_v1_5_shot",
          "inspect_evals/sec_qa_v2",
          "inspect_evals/sec_qa_v2_5_shot",
          "inspect_evals/sevenllm_mcq_en",
          "inspect_evals/sevenllm_mcq_zh",
          "inspect_evals/sevenllm_qa_en",
          "inspect_evals/sevenllm_qa_zh",
          "inspect_evals/simpleqa",
          "inspect_evals/sosbench",
          "inspect_evals/stereoset",
          "inspect_evals/strong_reject",
          "inspect_evals/sycophancy",
          "inspect_evals/truthfulqa",
          "inspect_evals/vstar_bench_attribute_recognition",
          "inspect_evals/vstar_bench_spatial_relationship_reasoning",
          "inspect_evals/winogrande",
          "inspect_evals/wmdp_bio",
          "inspect_evals/wmdp_chem",
          "inspect_evals/wmdp_cyber",
          "inspect_evals/xstest"
        ]
      }
    },
    "limit": {
      "type": "integer",
      "title": "Sample limit",
      "description": "Maximum number of samples to evaluate for each task (e.g. 5, 10, 25, 50).",
      "placeholder": "E.g. 5",
      "exclusiveMinimum": 0
    },
    "model": {
      "type": "object",
      "title": "Model",
      "description": "Model to use for the evaluation job",
      "properties": {
        "model_name": {
          "type": "string",
          "title": "Model name",
          "description": "Name of the model to use for the evaluation job.",
          "placeholder": "openai/gpt-4o"
        },
        "base_url": {
          "type": "string",
          "title": "Base URL",
          "description": "Base URL for the model to use for the evaluation job.",
          "placeholder": "https://api.openai.com/v1"
        },
        "api_key_var": {
          "type": "string",
          "title": "API key",
          "description": "API key for model access. Team secrets can be managed in your team settings by team admins.",
          "format": "secret"
        }
      }
    },
    "create_leaderboard": {
      "type": "boolean",
      "title": "Leaderboard",
      "label": "Publish results to leaderboard",
      "description": "Evaluation results will be shown in a leaderboard. Once generated, leaderboards can be found in the Leaders page of your project."
    },
    "hf_token": {
      "type": "string",
      "title": "Hugging Face token",
      "description": "(Optional) Personal access token used to read gated datasets from Hugging Face.",
      "format": "secret"
    },
    "scorer_api_key": {
      "type": "string",
      "title": "Scorer API key",
      "description": "(Optional) Some evals use an OpenAI model as the default scorer.",
      "format": "secret"
    }
  }
}
